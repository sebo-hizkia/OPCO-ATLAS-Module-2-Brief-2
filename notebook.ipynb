{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "850cff8e",
   "metadata": {},
   "source": [
    "## Analyse Exploratoire\n",
    "\n",
    "### Distribution\n",
    "![Distribution](imgs/Distribution.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c30a902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "matplotlib.use(\"Qt5Agg\")\n",
    "\n",
    "# Charger le CSV\n",
    "df = pd.read_csv(\"data/fichier-de-donnees-mixtes.csv\")\n",
    "\n",
    "# Encodage du sexe, smoker, sport_licence en entier 0 ou 1\n",
    "encoder = LabelEncoder()\n",
    "df[\"sexe_enc\"] = encoder.fit_transform(df[\"sexe\"])\n",
    "df[\"smoker_enc\"] = encoder.fit_transform(df[\"smoker\"])\n",
    "df[\"sport_licence_enc\"] = encoder.fit_transform(df[\"sport_licence\"])\n",
    "df[\"fr_enc\"] = encoder.fit_transform(df[\"nationalité_francaise\"])\n",
    "\n",
    "# Catégoriel\n",
    "df[\"situation_enc\"] = encoder.fit_transform(df[\"situation_familiale\"])\n",
    "df[\"region_enc\"] = encoder.fit_transform(df[\"region\"])\n",
    "\n",
    "# Ordinal\n",
    "ordre = [[\"aucun\", \"bac\", \"bac+2\", \"master\", \"doctorat\"]]\n",
    "ordinal_enc = OrdinalEncoder(categories=ordre)\n",
    "df[\"niv_etude_enc\"] = ordinal_enc.fit_transform(df[[\"niveau_etude\"]])\n",
    "\n",
    "# Extraction de l'année\n",
    "df[\"date_creation_compte\"] = pd.to_datetime(df[\"date_creation_compte\"], errors=\"coerce\")\n",
    "df[\"annee_creation\"] = df[\"date_creation_compte\"].dt.year\n",
    "\n",
    "\n",
    "# Description du fichier\n",
    "print(f\"Description : {df.describe}\")\n",
    "\n",
    "# Affichage de la distribution des données (les données sont toutes numériques)\n",
    "plt.figure(figsize=(15, 12))\n",
    "\n",
    "# Sélection des colonnes numériques uniquement\n",
    "num_cols = df.select_dtypes(include=\"number\").columns\n",
    "\n",
    "for i, col in enumerate(num_cols, 1):\n",
    "    plt.subplot(4, 5, i)     # 4x4\n",
    "    sns.histplot(df[col], kde=True, bins=30)\n",
    "    plt.title(f\"Distribution de {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Fréquence\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77103d9d-509d-45c8-88d2-0adc10e106c0",
   "metadata": {},
   "source": [
    "## Heatmap\n",
    "\n",
    "![Correlation](imgs/Correlation.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8cc4b39d-d7bd-42b8-829b-8d1b18d93b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap de corrélation\n",
    "plt.figure(figsize=(10, 8))\n",
    "corr = df.corr(numeric_only=True)\n",
    "\n",
    "sns.heatmap(corr, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Matrice de corrélation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240d0740-aff3-446c-aa1d-40f92e92353b",
   "metadata": {},
   "source": [
    "## Identifier les valeurs manquantes\n",
    "\n",
    "Utilisation de missingno\n",
    "\n",
    "![Colonnes manquantes](imgs/Colonnes.png)\n",
    "![Colonnes manquantes 2](imgs/Colonnes2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1860c490-c34c-4918-8d9c-88dc27bccdf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb lignes manquantes : 8802 / 10000\n"
     ]
    }
   ],
   "source": [
    "# Visualiser la matrice des valeurs manquantes\n",
    "msno.matrix(df)\n",
    "plt.show()\n",
    "\n",
    "# Visualiser le barplot des colonnes manquantes\n",
    "msno.bar(df)\n",
    "plt.show()\n",
    "\n",
    "# Nombre de lignes avec au moins une valeur manquante\n",
    "missing_line = df.isna().any(axis=1).sum()\n",
    "total_line = df.shape[0]\n",
    "print(f\"Nb lignes manquantes : {missing_line} / {total_line}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fdbe31-9165-4796-912f-f7457f45f12d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "245dc409-5842-4512-a746-ff898267a38e",
   "metadata": {},
   "source": [
    "## Nettoyage des Données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91c265d-f2f3-4cdc-b09a-1aa71f8c1e25",
   "metadata": {},
   "source": [
    "### Identifier les colonnes utiles au résultat\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd2643f-cdf3-41b9-b0b0-88a4f74f4ed1",
   "metadata": {},
   "source": [
    "### Supprimer les colonnes non pertinentes\n",
    "\n",
    "3 colonnes sont partielles, les autres sont complètes. Je fais donc le choix d'éliminer des colonnes plutôt que les lignes avec des données manquantes.\n",
    "Car si on éliminait les lignes incomplètes, on retirerait 8446 / 10000 lignes.\n",
    "\n",
    "Cependant, pour rester compatible avec de futures données, je supprime sur condition de pourcentage de données manquantes. Car s'il manque seulement 1 données dans une colonnes on ne va pas supprimer la colonne pour autant !\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6645e528-8843-4ce3-b3c8-4ec0b9cadcbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb colonnes avant nettoyage : 24, nb colonnes après : 20\n"
     ]
    }
   ],
   "source": [
    "cols_before = df.shape[1]\n",
    "threshold = 0.20  # 20%\n",
    "df_clean = df.drop(columns=df.columns[df.isna().mean() > threshold])\n",
    "cols_after = df_clean.shape[1]\n",
    "print(f\"Nb colonnes avant nettoyage : {cols_before}, nb colonnes après : {cols_after}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e236455-86fa-4ebb-969f-508986a3c4c8",
   "metadata": {},
   "source": [
    "Au cas où il resterait des lignes avec des champs manquants, je supprime les lignes concernée. Il n'y en a pas actuellement dans le jeu de données, mais cela pourrait être le cas dans le futur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "37ff389e-7728-4c9f-8089-e6495a459693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb lignes avant nettoyage : 10000, nb lignes après : 10000\n"
     ]
    }
   ],
   "source": [
    "lines_before = df_clean.shape[0]\n",
    "# Supprimer les lignes contenant des valeurs manquantes\n",
    "df_clean = df_clean.dropna()\n",
    "lines_after = df_clean.shape[0]\n",
    "print(f\"Nb lignes avant nettoyage : {lines_before}, nb lignes après : {lines_after}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c0b809-03ef-4baf-aa77-fddbf5f1d93a",
   "metadata": {},
   "source": [
    "### Ecarter les outliers\n",
    "Filtrer les outliers avec la méthode IQR (sur toutes les colonnes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c9449be7-4bf9-4f6d-b796-20a7ddc433f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb lignes avant filtrage des outliers : 10000, nb lignes après : 9751\n"
     ]
    }
   ],
   "source": [
    "# Sélection des colonnes numériques uniquement\n",
    "df_num = df_clean.select_dtypes(include=\"number\")\n",
    "\n",
    "lines_before = df_num.shape[0]\n",
    "Q1 = df_num.quantile(0.25)\n",
    "Q3 = df_num.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "df_filtered = df_num[~((df_num < (Q1 - 1.5 * IQR)) | (df_num > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "\n",
    "lines_after = df_filtered.shape[0]\n",
    "print(f\"Nb lignes avant filtrage des outliers : {lines_before}, nb lignes après : {lines_after}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88659902-9f74-426d-81e5-f1e1cd9ba06c",
   "metadata": {},
   "source": [
    "### Imputation\n",
    "Pas d'imputation dans ce cas, car une fois les colonnes quasi-vides enlevées, il n'y a pas de ligne avec des valeurs nulles. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6b2a16-8065-49c9-a809-1de0f67c08c5",
   "metadata": {},
   "source": [
    "### Catégorisation / Normalisation\n",
    "\n",
    "Toutes les colonnes sont de types numériques, donc pas besoin des catégoriser. Il faudra par contre les normaliser.\n",
    "\n",
    "#### Standardisation des données\n",
    "La standardisation consiste à transformer chaque variable pour qu’elle ait une moyenne de 0 et un écart-type de 1.  \n",
    "Cela permet de mettre toutes les colonnes numériques sur la même échelle, ce qui est essentiel pour de nombreux algorithmes de Machine Learning.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f9de2a07-92db-4fe3-b0ad-9e23855e4391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardisation effectuée (aperçu) :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>taille</th>\n",
       "      <th>poids</th>\n",
       "      <th>revenu_estime_mois</th>\n",
       "      <th>risque_personnel</th>\n",
       "      <th>montant_pret</th>\n",
       "      <th>sexe_enc</th>\n",
       "      <th>smoker_enc</th>\n",
       "      <th>sport_licence_enc</th>\n",
       "      <th>fr_enc</th>\n",
       "      <th>situation_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.571914</td>\n",
       "      <td>-0.910330</td>\n",
       "      <td>-0.192590</td>\n",
       "      <td>-1.447571</td>\n",
       "      <td>-1.338992</td>\n",
       "      <td>0.429579</td>\n",
       "      <td>1.001129</td>\n",
       "      <td>-1.008342</td>\n",
       "      <td>-0.969195</td>\n",
       "      <td>0.815904</td>\n",
       "      <td>-1.450626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.151545</td>\n",
       "      <td>-0.184470</td>\n",
       "      <td>0.327662</td>\n",
       "      <td>2.425334</td>\n",
       "      <td>1.002711</td>\n",
       "      <td>2.312510</td>\n",
       "      <td>1.001129</td>\n",
       "      <td>-1.008342</td>\n",
       "      <td>-0.969195</td>\n",
       "      <td>0.815904</td>\n",
       "      <td>-1.450626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.453054</td>\n",
       "      <td>-0.992117</td>\n",
       "      <td>-1.684891</td>\n",
       "      <td>1.142898</td>\n",
       "      <td>-1.270118</td>\n",
       "      <td>0.900855</td>\n",
       "      <td>1.001129</td>\n",
       "      <td>0.991727</td>\n",
       "      <td>-0.969195</td>\n",
       "      <td>0.815904</td>\n",
       "      <td>-1.450626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.918188</td>\n",
       "      <td>-0.828543</td>\n",
       "      <td>1.203875</td>\n",
       "      <td>0.700709</td>\n",
       "      <td>-0.615819</td>\n",
       "      <td>0.708102</td>\n",
       "      <td>-0.998873</td>\n",
       "      <td>0.991727</td>\n",
       "      <td>1.031784</td>\n",
       "      <td>0.815904</td>\n",
       "      <td>-0.757003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.696715</td>\n",
       "      <td>0.817420</td>\n",
       "      <td>0.512488</td>\n",
       "      <td>1.232041</td>\n",
       "      <td>0.555033</td>\n",
       "      <td>0.163597</td>\n",
       "      <td>-0.998873</td>\n",
       "      <td>-1.008342</td>\n",
       "      <td>1.031784</td>\n",
       "      <td>0.815904</td>\n",
       "      <td>-1.450626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age    taille     poids  revenu_estime_mois  risque_personnel  \\\n",
       "0  1.571914 -0.910330 -0.192590           -1.447571         -1.338992   \n",
       "1 -0.151545 -0.184470  0.327662            2.425334          1.002711   \n",
       "2  1.453054 -0.992117 -1.684891            1.142898         -1.270118   \n",
       "3  0.918188 -0.828543  1.203875            0.700709         -0.615819   \n",
       "4 -1.696715  0.817420  0.512488            1.232041          0.555033   \n",
       "\n",
       "   montant_pret  sexe_enc  smoker_enc  sport_licence_enc    fr_enc  \\\n",
       "0      0.429579  1.001129   -1.008342          -0.969195  0.815904   \n",
       "1      2.312510  1.001129   -1.008342          -0.969195  0.815904   \n",
       "2      0.900855  1.001129    0.991727          -0.969195  0.815904   \n",
       "3      0.708102 -0.998873    0.991727           1.031784  0.815904   \n",
       "4      0.163597 -0.998873   -1.008342           1.031784  0.815904   \n",
       "\n",
       "   situation_enc  \n",
       "0      -1.450626  \n",
       "1      -1.450626  \n",
       "2      -1.450626  \n",
       "3      -0.757003  \n",
       "4      -1.450626  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sauvegardé sous : data/dataset_standardized.csv\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialiser le scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Colonnes numériques (toutes celles de df_filtered)\n",
    "num_cols = df_filtered.select_dtypes(include=\"number\").columns\n",
    "\n",
    "# Copie du dataset\n",
    "df_standardized = df_filtered.copy()\n",
    "\n",
    "# Application de la standardisation\n",
    "df_standardized[num_cols] = scaler.fit_transform(df_filtered[num_cols])\n",
    "\n",
    "print(\"Standardisation effectuée (aperçu) :\")\n",
    "display(df_standardized.head())\n",
    "\n",
    "# Sauvegarde du dataset standardisé\n",
    "output_path = \"data/dataset_standardized.csv\"\n",
    "df_standardized.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Dataset sauvegardé sous : {output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6da938b6-2d99-4d8b-adc3-b7c0704ff36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap de corrélation sur les données nettoyées et standardisées\n",
    "plt.figure(figsize=(10, 8))\n",
    "corr = df_standardized.corr(numeric_only=True)\n",
    "\n",
    "sns.heatmap(corr, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Matrice de corrélation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefa7fc8-b2cf-4709-8813-921c027df9c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
