{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "850cff8e",
   "metadata": {},
   "source": [
    "## Analyse Exploratoire\n",
    "\n",
    "### Distribution\n",
    "![Distribution](imgs/Distribution.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0c30a902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description : <bound method NDFrame.describe of             nom   prenom  age  taille  poids sexe sport_licence niveau_etude  \\\n",
      "0       Ramirez    Casey   73   161.1   67.3    H           non       master   \n",
      "1          Hill  Phillip   44   168.2   74.9    H           non          bac   \n",
      "2     Hernandez   Martin   71   160.3   45.5    H           non     doctorat   \n",
      "3        Miller  Michael   62   161.9   87.7    F           oui          bac   \n",
      "4        Walker  Matthew   18   178.0   77.6    F           oui          bac   \n",
      "...         ...      ...  ...     ...    ...  ...           ...          ...   \n",
      "9995      Ortiz  Chelsea   37   163.6   96.7    F           non          bac   \n",
      "9996   Gonzalez   Edward   19   157.2   55.3    F           non          bac   \n",
      "9997     Potter  Allison   71   163.0   77.2    H           non        aucun   \n",
      "9998    Bonilla   Alyssa   54   165.7   73.2    H           oui        aucun   \n",
      "9999      Payne   Kristy   54   173.9   77.8    H           non       master   \n",
      "\n",
      "                    region smoker nationalité_francaise  revenu_estime_mois  \\\n",
      "0                Occitanie    non                   oui                 857   \n",
      "1            Île-de-France    non                   oui                5245   \n",
      "2     Auvergne-Rhône-Alpes    oui                   oui                3792   \n",
      "3     Auvergne-Rhône-Alpes    oui                   oui                3291   \n",
      "4                    Corse    non                   oui                3893   \n",
      "...                    ...    ...                   ...                 ...   \n",
      "9995  Auvergne-Rhône-Alpes    oui                   non                3894   \n",
      "9996  Auvergne-Rhône-Alpes    non                   oui                2969   \n",
      "9997             Normandie    oui                   non                2893   \n",
      "9998  Auvergne-Rhône-Alpes    oui                   non                1193   \n",
      "9999  Auvergne-Rhône-Alpes    oui                   oui                 500   \n",
      "\n",
      "     situation_familiale  historique_credits  risque_personnel  \\\n",
      "0            célibataire                 NaN              0.11   \n",
      "1            célibataire                 2.0              0.79   \n",
      "2            célibataire                 0.0              0.13   \n",
      "3                divorcé                 NaN              0.32   \n",
      "4            célibataire                 NaN              0.66   \n",
      "...                  ...                 ...               ...   \n",
      "9995                veuf                 1.0              0.63   \n",
      "9996               marié                 0.0              0.37   \n",
      "9997             divorcé                 NaN              0.56   \n",
      "9998                 NaN                 NaN              0.87   \n",
      "9999               marié                 NaN              0.70   \n",
      "\n",
      "     date_creation_compte  score_credit  loyer_mensuel  montant_pret  \n",
      "0              2024-09-28         615.0        1377.97  13157.101646  \n",
      "1              2023-06-26           NaN       10000.00  32408.309272  \n",
      "2              2023-06-13           NaN        5000.00  17975.461375  \n",
      "3              2024-01-12           NaN       10000.00  16004.737731  \n",
      "4              2023-02-16           NaN            NaN  10437.682760  \n",
      "...                   ...           ...            ...           ...  \n",
      "9995           2020-12-26           NaN        5000.00    500.000000  \n",
      "9996           2024-11-29           NaN         787.63   7671.982681  \n",
      "9997           2024-12-21           NaN        1184.94    500.000000  \n",
      "9998           2020-09-17           NaN            NaN    500.000000  \n",
      "9999           2021-12-04           NaN       10000.00   8162.127775  \n",
      "\n",
      "[10000 rows x 19 columns]>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "matplotlib.use(\"Qt5Agg\")\n",
    "\n",
    "# Charger le CSV\n",
    "df = pd.read_csv(\"data/fichier-de-donnees-mixtes.csv\")\n",
    "\n",
    "# Description du fichier\n",
    "print(f\"Description : {df.describe}\")\n",
    "\n",
    "# Encodage du sexe, smoker, sport_licence en entier 0 ou 1\n",
    "encoder = LabelEncoder()\n",
    "df[\"sexe\"] = encoder.fit_transform(df[\"sexe\"])\n",
    "df[\"smoker\"] = encoder.fit_transform(df[\"smoker\"])\n",
    "df[\"sport_licence\"] = encoder.fit_transform(df[\"sport_licence\"])\n",
    "df[\"nationalité_francaise\"] = encoder.fit_transform(df[\"nationalité_francaise\"])\n",
    "\n",
    "# Catégoriel\n",
    "mask = df[\"situation_familiale\"].notna()\n",
    "df.loc[mask, \"situation_familiale\"] = encoder.fit_transform(df.loc[mask, \"situation_familiale\"])\n",
    "df[\"region\"] = encoder.fit_transform(df[\"region\"])\n",
    "\n",
    "# Ordinal\n",
    "ordre = [[\"aucun\", \"bac\", \"bac+2\", \"master\", \"doctorat\"]]\n",
    "ordinal_enc = OrdinalEncoder(categories=ordre)\n",
    "df[\"niveau_etude\"] = ordinal_enc.fit_transform(df[[\"niveau_etude\"]])\n",
    "\n",
    "# Extraction de l'année\n",
    "df[\"date_creation_compte\"] = pd.to_datetime(df[\"date_creation_compte\"], errors=\"coerce\")\n",
    "df[\"date_creation_compte\"] = df[\"date_creation_compte\"].dt.year\n",
    "df.rename(columns={\"date_creation_compte\": \"annee_creation_compte\"})\n",
    "\n",
    "# Affichage de la distribution des données\n",
    "plt.figure(figsize=(15, 12))\n",
    "\n",
    "# Sélection des colonnes numériques uniquement\n",
    "num_cols = df.select_dtypes(include=\"number\").columns\n",
    "\n",
    "for i, col in enumerate(num_cols, 1):\n",
    "    plt.subplot(4, 5, i)     # 4x5\n",
    "    sns.histplot(df[col], kde=True, bins=30)\n",
    "    plt.title(f\"Distribution de {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Fréquence\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#display(df.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77103d9d-509d-45c8-88d2-0adc10e106c0",
   "metadata": {},
   "source": [
    "## Heatmap\n",
    "\n",
    "![Correlation](imgs/Correlation.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8cc4b39d-d7bd-42b8-829b-8d1b18d93b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Heatmap de corrélation\n",
    "plt.figure(figsize=(10, 8))\n",
    "corr = df.corr(numeric_only=True)\n",
    "\n",
    "sns.heatmap(corr, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Matrice de corrélation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240d0740-aff3-446c-aa1d-40f92e92353b",
   "metadata": {},
   "source": [
    "## Identifier les valeurs manquantes\n",
    "\n",
    "Utilisation de missingno\n",
    "\n",
    "![Colonnes manquantes](imgs/Colonnes.png)\n",
    "![Colonnes manquantes 2](imgs/Colonnes2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1860c490-c34c-4918-8d9c-88dc27bccdf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb lignes manquantes : 8802 / 10000\n"
     ]
    }
   ],
   "source": [
    "# Visualiser la matrice des valeurs manquantes\n",
    "msno.matrix(df)\n",
    "plt.show()\n",
    "\n",
    "# Visualiser le barplot des colonnes manquantes\n",
    "msno.bar(df)\n",
    "plt.show()\n",
    "\n",
    "# Nombre de lignes avec au moins une valeur manquante\n",
    "missing_line = df.isna().any(axis=1).sum()\n",
    "total_line = df.shape[0]\n",
    "print(f\"Nb lignes manquantes : {missing_line} / {total_line}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245dc409-5842-4512-a746-ff898267a38e",
   "metadata": {},
   "source": [
    "## Nettoyage des Données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91c265d-f2f3-4cdc-b09a-1aa71f8c1e25",
   "metadata": {},
   "source": [
    "### Identifier les colonnes utiles au résultat\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd2643f-cdf3-41b9-b0b0-88a4f74f4ed1",
   "metadata": {},
   "source": [
    "#### Supprimer les colonnes non pertinentes\n",
    "\n",
    "4 colonnes sont partielles, les autres sont complètes. Je fais le choix d'éliminer les colonnes avec beaucoup de données manquantes (> 40%).\n",
    "**historique_credit** et **score_credit** seront supprimées.\n",
    "Il restera **situation_familliale** et **loyer_mensuel**.\n",
    "**situation_familliale** n'est pas imputable, je la retire donc manuellement.\n",
    "Et pour **loyer_mensuel** je remplace les valeurs manquantes par la médiane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6645e528-8843-4ce3-b3c8-4ec0b9cadcbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb colonnes avant nettoyage : 19, nb colonnes après : 16\n"
     ]
    }
   ],
   "source": [
    "cols_before = df.shape[1]\n",
    "threshold = 0.40  # 40%\n",
    "a_supprimer = list(df.columns[df.isna().mean() > threshold]) + [\"situation_familiale\"]\n",
    "df_clean = df.drop(columns=a_supprimer)\n",
    "cols_after = df_clean.shape[1]\n",
    "print(f\"Nb colonnes avant nettoyage : {cols_before}, nb colonnes après : {cols_after}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88659902-9f74-426d-81e5-f1e1cd9ba06c",
   "metadata": {},
   "source": [
    "#### Imputation\n",
    "On remplit les valeurs manquantes de **loyer_mensuel** avec la valeur médiane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8d7d5354-f411-4468-a33b-89ed74ed3675",
   "metadata": {},
   "outputs": [],
   "source": [
    "nans_before = df_clean[\"loyer_mensuel\"].isna().sum()\n",
    "df_clean[\"loyer_mensuel\"] = df_clean[\"loyer_mensuel\"].fillna(df_clean[\"loyer_mensuel\"].median())\n",
    "nans_after = df_clean[\"loyer_mensuel\"].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e236455-86fa-4ebb-969f-508986a3c4c8",
   "metadata": {},
   "source": [
    "Au cas où il resterait des lignes avec des champs manquants, je supprime les lignes concernées. Il n'y en a pas actuellement dans le jeu de données, mais cela pourrait être le cas dans le futur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "37ff389e-7728-4c9f-8089-e6495a459693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb lignes avant nettoyage : 10000, nb lignes après : 10000\n"
     ]
    }
   ],
   "source": [
    "lines_before = df_clean.shape[0]\n",
    "# Supprimer les lignes contenant des valeurs manquantes\n",
    "df_clean = df_clean.dropna()\n",
    "lines_after = df_clean.shape[0]\n",
    "print(f\"Nb lignes avant nettoyage : {lines_before}, nb lignes après : {lines_after}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c0b809-03ef-4baf-aa77-fddbf5f1d93a",
   "metadata": {},
   "source": [
    "### Ecarter les outliers\n",
    "Filtrer les outliers avec la méthode IQR (sur toutes les colonnes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d43dbb7a-bf77-4afb-9d85-86b691aba350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb lignes avant filtrage des outliers : 10000, nb lignes après : 9751\n"
     ]
    }
   ],
   "source": [
    "lines_before = df_clean.shape[0]\n",
    "\n",
    "# Sélection des colonnes de type continu\n",
    "colonnes_outliers = [\"age\", \"taille\", \"poids\", \"revenu_estime_mois\", \"montant_pret\"]\n",
    "\n",
    "# On sélectionne uniquement ces colonnes (numeric obligatoire)\n",
    "df_num = df_clean[colonnes_outliers].select_dtypes(include=\"number\")\n",
    "\n",
    "# Calcul IQR\n",
    "Q1 = df_num.quantile(0.25)\n",
    "Q3 = df_num.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Détection des outliers uniquement sur ces colonnes\n",
    "mask_outliers = ((df_num < (Q1 - 1.5 * IQR)) | (df_num > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "\n",
    "# Suppression des lignes outliers dans le DF complet\n",
    "df_filtered = df_clean[~mask_outliers].copy()\n",
    "\n",
    "lines_after = df_filtered.shape[0]\n",
    "print(f\"Nb lignes avant filtrage des outliers : {lines_before}, nb lignes après : {lines_after}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6b2a16-8065-49c9-a809-1de0f67c08c5",
   "metadata": {},
   "source": [
    "#### Standardisation des données\n",
    "La standardisation consiste à transformer chaque variable pour qu’elle ait une moyenne de 0 et un écart-type de 1.  \n",
    "Cela permet de mettre toutes les colonnes numériques sur la même échelle, ce qui est essentiel pour de nombreux algorithmes de Machine Learning.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f9de2a07-92db-4fe3-b0ad-9e23855e4391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardisation effectuée (aperçu) :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nom</th>\n",
       "      <th>prenom</th>\n",
       "      <th>age</th>\n",
       "      <th>taille</th>\n",
       "      <th>poids</th>\n",
       "      <th>sexe</th>\n",
       "      <th>sport_licence</th>\n",
       "      <th>niveau_etude</th>\n",
       "      <th>region</th>\n",
       "      <th>smoker</th>\n",
       "      <th>nationalité_francaise</th>\n",
       "      <th>revenu_estime_mois</th>\n",
       "      <th>risque_personnel</th>\n",
       "      <th>date_creation_compte</th>\n",
       "      <th>loyer_mensuel</th>\n",
       "      <th>montant_pret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ramirez</td>\n",
       "      <td>Casey</td>\n",
       "      <td>1.571914</td>\n",
       "      <td>-0.910330</td>\n",
       "      <td>-0.192590</td>\n",
       "      <td>1.001129</td>\n",
       "      <td>-0.969195</td>\n",
       "      <td>0.722076</td>\n",
       "      <td>0.646162</td>\n",
       "      <td>-1.008342</td>\n",
       "      <td>0.815904</td>\n",
       "      <td>-1.447571</td>\n",
       "      <td>-1.338992</td>\n",
       "      <td>1.109858</td>\n",
       "      <td>-1.186436</td>\n",
       "      <td>0.429579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hill</td>\n",
       "      <td>Phillip</td>\n",
       "      <td>-0.151545</td>\n",
       "      <td>-0.184470</td>\n",
       "      <td>0.327662</td>\n",
       "      <td>1.001129</td>\n",
       "      <td>-0.969195</td>\n",
       "      <td>-0.689363</td>\n",
       "      <td>1.519263</td>\n",
       "      <td>-1.008342</td>\n",
       "      <td>0.815904</td>\n",
       "      <td>2.425334</td>\n",
       "      <td>1.002711</td>\n",
       "      <td>0.479817</td>\n",
       "      <td>1.542259</td>\n",
       "      <td>2.312510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hernandez</td>\n",
       "      <td>Martin</td>\n",
       "      <td>1.453054</td>\n",
       "      <td>-0.992117</td>\n",
       "      <td>-1.684891</td>\n",
       "      <td>1.001129</td>\n",
       "      <td>-0.969195</td>\n",
       "      <td>1.427795</td>\n",
       "      <td>-1.536589</td>\n",
       "      <td>0.991727</td>\n",
       "      <td>0.815904</td>\n",
       "      <td>1.142898</td>\n",
       "      <td>-1.270118</td>\n",
       "      <td>0.479817</td>\n",
       "      <td>-0.040138</td>\n",
       "      <td>0.900855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Miller</td>\n",
       "      <td>Michael</td>\n",
       "      <td>0.918188</td>\n",
       "      <td>-0.828543</td>\n",
       "      <td>1.203875</td>\n",
       "      <td>-0.998873</td>\n",
       "      <td>1.031784</td>\n",
       "      <td>-0.689363</td>\n",
       "      <td>-1.536589</td>\n",
       "      <td>0.991727</td>\n",
       "      <td>0.815904</td>\n",
       "      <td>0.700709</td>\n",
       "      <td>-0.615819</td>\n",
       "      <td>1.109858</td>\n",
       "      <td>1.542259</td>\n",
       "      <td>0.708102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Walker</td>\n",
       "      <td>Matthew</td>\n",
       "      <td>-1.696715</td>\n",
       "      <td>0.817420</td>\n",
       "      <td>0.512488</td>\n",
       "      <td>-0.998873</td>\n",
       "      <td>1.031784</td>\n",
       "      <td>-0.689363</td>\n",
       "      <td>-0.663488</td>\n",
       "      <td>-1.008342</td>\n",
       "      <td>0.815904</td>\n",
       "      <td>1.232041</td>\n",
       "      <td>0.555033</td>\n",
       "      <td>0.479817</td>\n",
       "      <td>-0.040138</td>\n",
       "      <td>0.163597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         nom   prenom       age    taille     poids      sexe  sport_licence  \\\n",
       "0    Ramirez    Casey  1.571914 -0.910330 -0.192590  1.001129      -0.969195   \n",
       "1       Hill  Phillip -0.151545 -0.184470  0.327662  1.001129      -0.969195   \n",
       "2  Hernandez   Martin  1.453054 -0.992117 -1.684891  1.001129      -0.969195   \n",
       "3     Miller  Michael  0.918188 -0.828543  1.203875 -0.998873       1.031784   \n",
       "4     Walker  Matthew -1.696715  0.817420  0.512488 -0.998873       1.031784   \n",
       "\n",
       "   niveau_etude    region    smoker  nationalité_francaise  \\\n",
       "0      0.722076  0.646162 -1.008342               0.815904   \n",
       "1     -0.689363  1.519263 -1.008342               0.815904   \n",
       "2      1.427795 -1.536589  0.991727               0.815904   \n",
       "3     -0.689363 -1.536589  0.991727               0.815904   \n",
       "4     -0.689363 -0.663488 -1.008342               0.815904   \n",
       "\n",
       "   revenu_estime_mois  risque_personnel  date_creation_compte  loyer_mensuel  \\\n",
       "0           -1.447571         -1.338992              1.109858      -1.186436   \n",
       "1            2.425334          1.002711              0.479817       1.542259   \n",
       "2            1.142898         -1.270118              0.479817      -0.040138   \n",
       "3            0.700709         -0.615819              1.109858       1.542259   \n",
       "4            1.232041          0.555033              0.479817      -0.040138   \n",
       "\n",
       "   montant_pret  \n",
       "0      0.429579  \n",
       "1      2.312510  \n",
       "2      0.900855  \n",
       "3      0.708102  \n",
       "4      0.163597  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sauvegardé sous : data/dataset_standardized.csv\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialiser le scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Colonnes numériques\n",
    "num_cols = df_filtered.select_dtypes(include=\"number\").columns\n",
    "\n",
    "# Copie du dataset\n",
    "df_standardized = df_filtered.copy()\n",
    "\n",
    "# Application de la standardisation\n",
    "df_standardized[num_cols] = scaler.fit_transform(df_filtered[num_cols])\n",
    "\n",
    "print(\"Standardisation effectuée (aperçu) :\")\n",
    "display(df_standardized.head())\n",
    "\n",
    "# Sauvegarde du dataset standardisé\n",
    "output_path = \"data/dataset_standardized.csv\"\n",
    "df_standardized.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Dataset sauvegardé sous : {output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6da938b6-2d99-4d8b-adc3-b7c0704ff36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Heatmap de corrélation sur les données nettoyées et standardisées\n",
    "plt.figure(figsize=(10, 8))\n",
    "corr = df_standardized.corr(numeric_only=True)\n",
    "\n",
    "sns.heatmap(corr, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Matrice de corrélation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13157f3-c45b-44b2-bb0d-417147ea3139",
   "metadata": {},
   "source": [
    "### Analyse\n",
    "D'après la matrice, nous constatons que le sexe et la nationnalité sont en corrélation avec l'estimation du prêt. Le jeu de données est donc biaisé. Garder ces données provoquerait de la discrimination.\n",
    "\n",
    "Dans la version éthique du jeu de données, je supprime les colonnes suivantes :\n",
    "- nom et prénom : ce sont des données d'identification directe\n",
    "- nationnalité et sexe qui dont des données sensibles interdites par la RGPD\n",
    "- smoker qui est une données de santé et potentiellement discriminatoire\n",
    "- situation_familiale qui est une données personnelle et provoquerait de la discrimination entre personne seules ou en couple (à de toute façon était supprimé en amont pour manque de données)\n",
    "- risque_personnel : variable non neutre donc à sortir d'un jeu de données éthique, même si dans zone grise de la RGPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "eefa7fc8-b2cf-4709-8813-921c027df9c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['situation_familiale'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Création de la version éthique : suppression des variables sensibles\u001b[39;00m\n\u001b[1;32m      2\u001b[0m colonnes_sensibles \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnom\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprenom\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msexe\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msmoker\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnationalité_francaise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msituation_familiale\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrisque_personnel\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m ]\n\u001b[0;32m----> 7\u001b[0m df_ethic \u001b[38;5;241m=\u001b[39m \u001b[43mdf_standardized\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolonnes_sensibles\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m output_ethic \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/dataset_ethic.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m df_ethic\u001b[38;5;241m.\u001b[39mto_csv(output_ethic, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Developpement/Simplon/OPCO-ATLAS-Module-2-Brief-2/.venv/lib/python3.10/site-packages/pandas/core/frame.py:5603\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5455\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   5456\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5457\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5464\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5465\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5466\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5467\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5468\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5601\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5602\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5603\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5605\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5606\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5607\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5609\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5610\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5611\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Developpement/Simplon/OPCO-ATLAS-Module-2-Brief-2/.venv/lib/python3.10/site-packages/pandas/core/generic.py:4810\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4808\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4809\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4810\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4813\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/Developpement/Simplon/OPCO-ATLAS-Module-2-Brief-2/.venv/lib/python3.10/site-packages/pandas/core/generic.py:4852\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4850\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4851\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4852\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4853\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4855\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4856\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Developpement/Simplon/OPCO-ATLAS-Module-2-Brief-2/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:7136\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   7134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   7135\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 7136\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   7137\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   7138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['situation_familiale'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# Création de la version éthique : suppression des variables sensibles\n",
    "colonnes_sensibles = [\n",
    "    \"nom\", \"prenom\", \"sexe\", \"smoker\", \"nationalité_francaise\", \"risque_personnel\"\n",
    "]\n",
    "\n",
    "df_ethic = df_standardized.drop(columns=colonnes_sensibles)\n",
    "\n",
    "output_ethic = \"data/dataset_ethic.csv\"\n",
    "df_ethic.to_csv(output_ethic, index=False)\n",
    "\n",
    "print(f\"Dataset éthique sauvegardé sous : {output_ethic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19fb3c1-e3c7-4ae3-85b7-482169111dd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
