{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "850cff8e",
   "metadata": {},
   "source": [
    "## Analyse Exploratoire\n",
    "\n",
    "### Distribution\n",
    "![Distribution](imgs/Distribution.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c30a902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description : <bound method NDFrame.describe of       age  taille  poids  revenu_estime_mois  historique_credits  \\\n",
      "0      73   161.1   67.3                 857                 NaN   \n",
      "1      44   168.2   74.9                5245                 2.0   \n",
      "2      71   160.3   45.5                3792                 0.0   \n",
      "3      62   161.9   87.7                3291                 NaN   \n",
      "4      18   178.0   77.6                3893                 NaN   \n",
      "...   ...     ...    ...                 ...                 ...   \n",
      "9995   37   163.6   96.7                3894                 1.0   \n",
      "9996   19   157.2   55.3                2969                 0.0   \n",
      "9997   71   163.0   77.2                2893                 NaN   \n",
      "9998   54   165.7   73.2                1193                 NaN   \n",
      "9999   54   173.9   77.8                 500                 NaN   \n",
      "\n",
      "      risque_personnel  score_credit  loyer_mensuel  montant_pret  \n",
      "0                 0.11         615.0        1377.97  13157.101646  \n",
      "1                 0.79           NaN       10000.00  32408.309272  \n",
      "2                 0.13           NaN        5000.00  17975.461375  \n",
      "3                 0.32           NaN       10000.00  16004.737731  \n",
      "4                 0.66           NaN            NaN  10437.682760  \n",
      "...                ...           ...            ...           ...  \n",
      "9995              0.63           NaN        5000.00    500.000000  \n",
      "9996              0.37           NaN         787.63   7671.982681  \n",
      "9997              0.56           NaN        1184.94    500.000000  \n",
      "9998              0.87           NaN            NaN    500.000000  \n",
      "9999              0.70           NaN       10000.00   8162.127775  \n",
      "\n",
      "[10000 rows x 9 columns]>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.use(\"Qt5Agg\")\n",
    "\n",
    "# Charger le CSV\n",
    "df = pd.read_csv(\"data/fichier-de-donnees-numeriques.csv\")\n",
    "\n",
    "# Description du fichier\n",
    "print(f\"Description : {df.describe}\")\n",
    "\n",
    "# Affichage de la distribution des données (les données sont toutes numériques)\n",
    "plt.figure(figsize=(15, 12))\n",
    "\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    plt.subplot(3, 3, i)     # 3x3 pour 9 colonnes\n",
    "    sns.histplot(df[col], kde=True, bins=30)\n",
    "    plt.title(f\"Distribution de {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Fréquence\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77103d9d-509d-45c8-88d2-0adc10e106c0",
   "metadata": {},
   "source": [
    "## Heatmap\n",
    "\n",
    "![Correlation](imgs/Correlation.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cc4b39d-d7bd-42b8-829b-8d1b18d93b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap de corrélation\n",
    "plt.figure(figsize=(10, 8))\n",
    "corr = df.corr(numeric_only=True)\n",
    "\n",
    "sns.heatmap(corr, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Matrice de corrélation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240d0740-aff3-446c-aa1d-40f92e92353b",
   "metadata": {},
   "source": [
    "## Identifier les valeurs manquantes\n",
    "\n",
    "Utilisation de missingno\n",
    "\n",
    "![Colonnes manquantes](imgs/Colonnes.png)\n",
    "![Colonnes manquantes 2](imgs/Colonnes2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1860c490-c34c-4918-8d9c-88dc27bccdf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb lignes manquantes : 8446 / 10000\n"
     ]
    }
   ],
   "source": [
    "# Visualiser la matrice des valeurs manquantes\n",
    "msno.matrix(df)\n",
    "plt.show()\n",
    "\n",
    "# Visualiser le barplot des colonnes manquantes\n",
    "msno.bar(df)\n",
    "plt.show()\n",
    "\n",
    "# Nombre de lignes avec au moins une valeur manquante\n",
    "missing_line = df.isna().any(axis=1).sum()\n",
    "total_line = df.shape[0]\n",
    "print(f\"Nb lignes manquantes : {missing_line} / {total_line}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fdbe31-9165-4796-912f-f7457f45f12d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "245dc409-5842-4512-a746-ff898267a38e",
   "metadata": {},
   "source": [
    "## Nettoyage des Données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91c265d-f2f3-4cdc-b09a-1aa71f8c1e25",
   "metadata": {},
   "source": [
    "### Identifier les colonnes utiles au résultat\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd2643f-cdf3-41b9-b0b0-88a4f74f4ed1",
   "metadata": {},
   "source": [
    "### Supprimer les colonnes non pertinentes\n",
    "\n",
    "3 colonnes sont partielles, les autres sont complètes. Je fais donc le choix d'éliminer des colonnes plutôt que les lignes avec des données manquantes.\n",
    "Car si on éliminait les lignes incomplètes, on retirerait 8446 / 10000 lignes.\n",
    "\n",
    "Cependant, pour rester compatible avec de futures données, je supprime sur condition de pourcentage de données manquantes. Car s'il manque seulement 1 données dans une colonnes on ne va pas supprimer la colonne pour autant !\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6645e528-8843-4ce3-b3c8-4ec0b9cadcbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb colonnes avant nettoyage : 9, nb colonnes après : 6\n"
     ]
    }
   ],
   "source": [
    "cols_before = df.shape[1]\n",
    "threshold = 0.20  # 20%\n",
    "df_clean = df.drop(columns=df.columns[df.isna().mean() > threshold])\n",
    "cols_after = df_clean.shape[1]\n",
    "print(f\"Nb colonnes avant nettoyage : {cols_before}, nb colonnes après : {cols_after}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e236455-86fa-4ebb-969f-508986a3c4c8",
   "metadata": {},
   "source": [
    "Au cas où il resterait des lignes avec des champs manquants, je supprime les lignes concernée. Il n'y en a pas actuellement dans le jeu de données, mais cela pourrait être le cas dans le futur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37ff389e-7728-4c9f-8089-e6495a459693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb lignes avant nettoyage : 10000, nb lignes après : 10000\n"
     ]
    }
   ],
   "source": [
    "lines_before = df_clean.shape[0]\n",
    "# Supprimer les lignes contenant des valeurs manquantes\n",
    "df_clean = df_clean.dropna()\n",
    "lines_after = df_clean.shape[0]\n",
    "print(f\"Nb lignes avant nettoyage : {lines_before}, nb lignes après : {lines_after}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c0b809-03ef-4baf-aa77-fddbf5f1d93a",
   "metadata": {},
   "source": [
    "### Ecarter les outliers\n",
    "Filtrer les outliers avec la méthode IQR (sur toutes les colonnes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9449be7-4bf9-4f6d-b796-20a7ddc433f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb lignes avant filtrage des outliers : 10000, nb lignes après : 9751\n"
     ]
    }
   ],
   "source": [
    "lines_before = df_clean.shape[0]\n",
    "Q1 = df_clean.quantile(0.25)\n",
    "Q3 = df_clean.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "df_filtered = df_clean[~((df_clean < (Q1 - 1.5 * IQR)) | (df_clean > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "\n",
    "lines_after = df_filtered.shape[0]\n",
    "print(f\"Nb lignes avant filtrage des outliers : {lines_before}, nb lignes après : {lines_after}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88659902-9f74-426d-81e5-f1e1cd9ba06c",
   "metadata": {},
   "source": [
    "### Imputation\n",
    "Pas d'imputation dans ce cas, car une fois les colonnes quasi-vides enlevées, il n'y a pas de ligne avec des valeurs nulles. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6b2a16-8065-49c9-a809-1de0f67c08c5",
   "metadata": {},
   "source": [
    "### Catégorisation / Normalisation\n",
    "\n",
    "Toutes les colonnes sont de types numériques, donc pas besoin des catégoriser. Il faudra par contre les normaliser.\n",
    "\n",
    "#### Standardisation des données\n",
    "La standardisation consiste à transformer chaque variable pour qu’elle ait une moyenne de 0 et un écart-type de 1.  \n",
    "Cela permet de mettre toutes les colonnes numériques sur la même échelle, ce qui est essentiel pour de nombreux algorithmes de Machine Learning.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9de2a07-92db-4fe3-b0ad-9e23855e4391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardisation effectuée (aperçu) :\n",
      "Dataset sauvegardé sous : data/dataset_standardized.csv\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialiser le scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Colonnes numériques (toutes celles de df_filtered)\n",
    "num_cols = df_filtered.select_dtypes(include=\"number\").columns\n",
    "\n",
    "# Copie du dataset\n",
    "df_standardized = df_filtered.copy()\n",
    "\n",
    "# Application de la standardisation\n",
    "df_standardized[num_cols] = scaler.fit_transform(df_filtered[num_cols])\n",
    "\n",
    "print(\"Standardisation effectuée (aperçu) :\")\n",
    "display(df_standardized.head())\n",
    "\n",
    "# Sauvegarde du dataset standardisé\n",
    "output_path = \"data/dataset_standardized.csv\"\n",
    "df_standardized.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Dataset sauvegardé sous : {output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da938b6-2d99-4d8b-adc3-b7c0704ff36c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
